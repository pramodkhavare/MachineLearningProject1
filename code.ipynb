{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PramodABC\n"
     ]
    }
   ],
   "source": [
    "name = 'Pramod'\n",
    "surname = 'khavare'\n",
    "\n",
    "abc= name+\"ABC\" \n",
    "print(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\\\artifact\\data_ingestion\\\\2024-03-23-19-59-41\\\\ingested_data\\\\test\\\\test_data_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'float64',\n",
       " 'object']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types = list(map(lambda x : str(x).replace(\"dtype('\" ,\"\"),df.dtypes.values))\n",
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longitude': 'float64',\n",
       " 'latitude': 'float64',\n",
       " 'housing_median_age': 'float64',\n",
       " 'total_rooms': 'float64',\n",
       " 'total_bedrooms': 'float64',\n",
       " 'population': 'float64',\n",
       " 'households': 'float64',\n",
       " 'median_income': 'float64',\n",
       " 'median_house_value': 'float64',\n",
       " 'ocean_proximity': 'object'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(columns ,data_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-121.09</td>\n",
       "      <td>39.48</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-121.21</td>\n",
       "      <td>39.49</td>\n",
       "      <td>18.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-121.22</td>\n",
       "      <td>39.43</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-121.32</td>\n",
       "      <td>39.43</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-121.24</td>\n",
       "      <td>39.37</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                41.0        880.0           129.0   \n",
       "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2        -122.24     37.85                52.0       1467.0           190.0   \n",
       "3        -122.25     37.85                52.0       1274.0           235.0   \n",
       "4        -122.25     37.85                52.0       1627.0           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
       "20636    -121.21     39.49                18.0        697.0           150.0   \n",
       "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
       "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
       "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0           322.0       126.0         8.3252            452600.0   \n",
       "1          2401.0      1138.0         8.3014            358500.0   \n",
       "2           496.0       177.0         7.2574            352100.0   \n",
       "3           558.0       219.0         5.6431            341300.0   \n",
       "4           565.0       259.0         3.8462            342200.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635       845.0       330.0         1.5603             78100.0   \n",
       "20636       356.0       114.0         2.5568             77100.0   \n",
       "20637      1007.0       433.0         1.7000             92300.0   \n",
       "20638       741.0       349.0         1.8672             84700.0   \n",
       "20639      1387.0       530.0         2.3886             89400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_ =pd.read_csv('D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\\\artifact\\data_ingestion\\\\2024-03-22-13-06-46\\\\raw_data\\housing.csv')\n",
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pramod\n",
      "I love you\n"
     ]
    }
   ],
   "source": [
    "name = False\n",
    "surname = True \n",
    "if  name ==False :\n",
    "    print('Pramod')\n",
    "\n",
    "if not name:\n",
    "    print(\"I love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List is not empty\n"
     ]
    }
   ],
   "source": [
    "empty_list = []\n",
    "if not empty_list:\n",
    "    print('List is not empty')\n",
    "if empty_list == False:\n",
    "    print('List is False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame({'A':[1,2,3,4] , 'B':[1,4,9,16]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B\n",
       "0  1   1\n",
       "1  2   4\n",
       "2  3   9\n",
       "3  4  16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\\\artifact\\data_ingestion\\\\2024-03-23-19-59-41\\\\ingested_data\\\\test\\\\test_data_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-118.39</td>\n",
       "      <td>34.12</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6447.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>8.2816</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-120.42</td>\n",
       "      <td>34.89</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>5.0099</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-118.45</td>\n",
       "      <td>34.25</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1453.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>4.3839</td>\n",
       "      <td>204600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-118.10</td>\n",
       "      <td>33.91</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>3.2708</td>\n",
       "      <td>159700.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-117.07</td>\n",
       "      <td>32.77</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>4.3529</td>\n",
       "      <td>184000.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -118.39     34.12                29.0       6447.0          1012.0   \n",
       "1    -120.42     34.89                24.0       2020.0           307.0   \n",
       "2    -118.45     34.25                36.0       1453.0           270.0   \n",
       "3    -118.10     33.91                35.0       1653.0           325.0   \n",
       "4    -117.07     32.77                38.0       3779.0           614.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0      2184.0       960.0         8.2816            500001.0       <1H OCEAN  \n",
       "1       855.0       283.0         5.0099            162500.0       <1H OCEAN  \n",
       "2       808.0       275.0         4.3839            204600.0       <1H OCEAN  \n",
       "3      1072.0       301.0         3.2708            159700.0       <1H OCEAN  \n",
       "4      1495.0       614.0         4.3529            184000.0      NEAR OCEAN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'median_house_value',\n",
       " 'ocean_proximity']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\"A\" , \"B\" ,\"C\" ,\"D\" ,\"E\"]\n",
    "list2 = [\"A\" , \"B\" ,\"C\" ,\"D\" ,\"F\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lists(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    return bool(set1.intersection(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_lists(list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\"A\" , \"B\" ,\"C\" ,\"D\" ,\"E\"]\n",
    "list2 = [\"A\" , \"B\" ,\"C\" ,\"D\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_lists1(list1, list2):\n",
    "    for item1 in list1:\n",
    "        for item2 in list2:\n",
    "            if item1 == item2:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "compare_lists1(list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1,2,3]\n",
    "list2 = [1,2,3]\n",
    "# compare_lists1(list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lists_match(list1, list2):\n",
    "    # Check if the lengths of the lists are different\n",
    "    if len(list1) != len(list2):\n",
    "        return False\n",
    "    \n",
    "    # Compare each element of the lists\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] != list2[i]:\n",
    "            return False  # If any element doesn't match, return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\\\artifact\\\\data_ingestion\\\\2024-03-24-15-30-21\\\\ingested_data\\\\train\\\\train_data_housing.csv\"\n",
    "test_file_path =  \"D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\\\artifact\\\\data_ingestion\\\\2024-03-24-15-30-21\\\\ingested_data\\\\test\\\\test_data_housing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "target_column ='median_house_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X ,y = train_data.drop(columns=[target_column]) ,train_data[[target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from Housing.src.exception import HousingException\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TOTAL_ROOMS = 'total_rooms' \n",
    "COLUMN_POPULATION = 'population'\n",
    "COLUMN_TOTAL_BEDROOMS = 'total_bedrooms'\n",
    "COLUMN_HOUSEHOLDS = 'households' \n",
    "\n",
    "\n",
    "class FeatureGenerator(BaseEstimator ,TransformerMixin):\n",
    "    def __init__(self ,add_bedroom_per_romm =True ,\n",
    "                 total_room_ix = 3,\n",
    "                 population_ix = 5 ,\n",
    "                 households_ix = 6 ,\n",
    "                 total_bedroom_ix = 4 ,\n",
    "                 columns =None):\n",
    "        \"\"\"\n",
    "        total_room_ix,population_ix ,households_ix ,total_bedroom_ix are id of these column inside dataset\n",
    "        \"\"\" \n",
    "\n",
    "        try:\n",
    "            \n",
    "            self.columns = columns \n",
    "            if self.columns is not None:\n",
    "                total_room_ix =self.columns.index(COLUMN_TOTAL_ROOMS)\n",
    "                population_ix = self.columns.index(COLUMN_POPULATION)\n",
    "                total_bedroom_ix = self.columns.index(COLUMN_TOTAL_BEDROOMS)\n",
    "                households_ix = self.columns.index(COLUMN_HOUSEHOLDS)\n",
    "            \n",
    "            self.add_bedroom_per_romm = add_bedroom_per_romm  \n",
    "            self.total_room_ix = total_room_ix \n",
    "            self.population_ix =population_ix \n",
    "            self.households_ix =households_ix \n",
    "            self.total_bedroom_ix = total_bedroom_ix\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HousingException(e,sys) from e\n",
    "        \n",
    "    def fit(self ,X,y=None):\n",
    "        return self  \n",
    "    \n",
    "\n",
    "\n",
    "    def transform(self ,X ,y=None):\n",
    "        try:\n",
    "            room_per_households = X[: ,self.total_room_ix] / X[: ,self.total_bedroom_ix]\n",
    "            population_per_households = X[: ,self.population_ix] / X[: ,self.households_ix]\n",
    "            bedroom_per_room = X[: ,self.total_bedroom_ix]/X[: ,self.total_room_ix]\n",
    "            if self.add_bedroom_per_romm:\n",
    "                generated_feature = np.c_[\n",
    "                    X ,room_per_households , population_per_households,bedroom_per_room\n",
    "                ]\n",
    "            else:\n",
    "                generated_feature = np.c_[X,room_per_households ,population_per_households]\n",
    "            \n",
    "            return generated_feature\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise HousingException(e,sys) from e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from Housing.src.exception import HousingException\n",
    "import os,sys\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('impute' ,SimpleImputer(strategy='median')) ,\n",
    "        ('feature_generator' ,FeatureGenerator()) ,\n",
    "        ('scalar' ,StandardScaler())\n",
    "    ]\n",
    ")\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('impute' ,SimpleImputer(strategy='most_frequent')) ,\n",
    "        ('encode' ,OneHotEncoder()) ,\n",
    "        ('scalar' ,StandardScaler(with_mean=False))\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = train_data.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-60.67637885,  18.01769717,   2.30626612, ...,   1.87923503,\n",
       "          1.14107355,   0.62317524],\n",
       "       [-58.56324628,  15.4778193 ,   0.55668493, ...,   2.04426701,\n",
       "          3.32688875,   2.41664073],\n",
       "       [-59.46744721,  16.54428736,   3.4991624 , ...,   0.7985418 ,\n",
       "          1.5092871 ,   0.71479323],\n",
       "       ...,\n",
       "       [-61.3058226 ,  17.98027724,   3.81726807, ...,   0.45783063,\n",
       "          1.66924529,   1.21350629],\n",
       "       [-61.29583143,  17.91946985,   1.11336985, ...,   1.33356481,\n",
       "          2.2029817 ,   2.23081177],\n",
       "       [-61.01607865,  18.69593344,   2.14721329, ...,   0.52437578,\n",
       "          1.64415175,   0.54192909]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc= StandardScaler(with_mean=False)\n",
    "abc.fit_transform(num_data)\n",
    "abc.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_column = X.select_dtypes(exclude= 'object').columns\n",
    "cat_column = X.select_dtypes(include= 'object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipeline' , num_pipeline ,num_column) ,\n",
    "    ('cat_pipeline' ,cat_pipeline ,cat_column)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94135046,  1.34743822,  0.02756357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.17178212, -1.19243966, -1.72201763, ...,  0.        ,\n",
       "         0.        ,  2.9869105 ],\n",
       "       [ 0.26758118, -0.1259716 ,  1.22045984, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.5707942 ,  1.31001828,  1.53856552, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.56080303,  1.2492109 , -1.1653327 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.28105026,  2.02567448, -0.13148926, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(num_column).index(COLUMN_HOUSEHOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Housing.src.utils.utils import read_yaml \n",
    "dataset_schema =read_yaml('D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\config\\schema.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'longitude': 'float64',\n",
       " 'latitude': 'float64',\n",
       " 'housing_median_age': 'float64',\n",
       " 'total_rooms': 'float64',\n",
       " 'total_bedrooms': 'float64',\n",
       " 'population': 'float64',\n",
       " 'households': 'float64',\n",
       " 'median_income': 'float64',\n",
       " 'median_house_value': 'float64',\n",
       " 'ocean_proximity': 'object'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_schema['columns']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_FILE_COLUMN_KEY = 'columns'\n",
    "schema = dataset_schema[SCHEMA_FILE_COLUMN_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.columns:\n",
    "    if column in list(schema.keys()):\n",
    "        train_data[column].astype(schema[column])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude\n",
      "latitude\n",
      "housing_median_age\n",
      "total_rooms\n",
      "total_bedrooms\n",
      "population\n",
      "households\n",
      "median_income\n",
      "median_house_value\n",
      "ocean_proximity\n"
     ]
    }
   ],
   "source": [
    "for column in schema.keys():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.read_csv(r\"D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\artifact\\data_ingestion\\2024-03-15-21-57-27\\raw_data\\housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file_path = r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\config\\config.yaml'\n",
    "yaml_file_path2 =r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\config\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_pipeline_config': {'pipeline_name': 'housing',\n",
       "  'artifact_dir': 'artifact'},\n",
       " 'data_ingestion_config': {'data_ingestion_dir': 'data_ingestion',\n",
       "  'dataset_download_url': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz',\n",
       "  'tgz_download_dir': 'tgz_data',\n",
       "  'raw_data_dir': 'raw_data',\n",
       "  'ingested_dir': 'ingested_data',\n",
       "  'ingested_train_dir': 'train',\n",
       "  'ingested_test_dir': 'test'},\n",
       " 'data_validation_config': {'data_validation_dir': 'data_validation',\n",
       "  'schema_dir': 'config',\n",
       "  'schema_file_name': 'schema.yaml',\n",
       "  'report_file_name': 'report.json',\n",
       "  'report_page_file_name': 'report.html'},\n",
       " 'data_transformation_config': {'add_bedroom_per_room': True,\n",
       "  'transformed_dir': 'transformed_data_dir',\n",
       "  'transformed_train_dir': 'train',\n",
       "  'transformed_test_dir': 'test',\n",
       "  'preprocessing_dir': 'preprocessed_obj',\n",
       "  'preprocessing_object_file_name': 'preprocessed.pkl'},\n",
       " 'model_training_config': {'trained_model_file_name': 'trained_model',\n",
       "  'model_file_name': 'model.pkl',\n",
       "  'base_accuracy': 0.6},\n",
       " 'model_evaluation_config': {'model_evaluation_file_name': 'model_evaluation.yaml'},\n",
       " 'model_pusher_config': {'export_dir_path': 'saved_models'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Housing.src.utils.utils import read_yaml\n",
    "read_yaml(yaml_file_path=yaml_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.columns:\n",
    "    if column in list(schema.keys()):\n",
    "        train_data[column].astype(schema[column])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_datahousing.npz'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\\\artifact\\data_ingestion\\\\2024-03-15-21-57-27\\ingested_data\\\\test\\\\test_datahousing.csv'\n",
    "os.path.basename(file).replace('.csv' ,'.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Housing.src.config.configuration import HousingConfiguration \n",
    "import os ,sys \n",
    "from Housing.src.entity.config_entity import DataTransfrmationConfig  \n",
    "from Housing.src.entity.artifact_entity import  DataIngestionArtifact ,DataValidationArtifacts ,DataTransformationArtifact\n",
    "from Housing.src.logger import logging \n",
    "from Housing.src.exception import HousingException \n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler ,OneHotEncoder \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from Housing.src.utils.utils import read_yaml ,save_numpy_array  ,save_pickle\n",
    "from Housing.src.constant import *\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TOTAL_ROOMS = 'total_rooms' \n",
    "COLUMN_POPULATION = 'population'\n",
    "COLUMN_TOTAL_BEDROOMS = 'total_bedrooms'\n",
    "COLUMN_HOUSEHOLDS = 'households' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, add_bedrooms_per_room=True,\n",
    "                 total_rooms_ix=3,\n",
    "                 population_ix=5,\n",
    "                 households_ix=6,\n",
    "                 total_bedrooms_ix=4, columns=None):\n",
    "        \"\"\"\n",
    "        FeatureGenerator Initialization\n",
    "        add_bedrooms_per_room: bool\n",
    "        total_rooms_ix: int index number of total rooms columns\n",
    "        population_ix: int index number of total population columns\n",
    "        households_ix: int index number of  households columns\n",
    "        total_bedrooms_ix: int index number of bedrooms columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.columns = columns\n",
    "            if self.columns is not None:\n",
    "                total_rooms_ix = self.columns.index(COLUMN_TOTAL_ROOMS)\n",
    "                population_ix = self.columns.index(COLUMN_POPULATION)\n",
    "                households_ix = self.columns.index(COLUMN_HOUSEHOLDS)\n",
    "                total_bedrooms_ix = self.columns.index(COLUMN_TOTAL_BEDROOMS)\n",
    "\n",
    "            self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "            self.total_rooms_ix = total_rooms_ix\n",
    "            self.population_ix = population_ix\n",
    "            self.households_ix = households_ix\n",
    "            self.total_bedrooms_ix = total_bedrooms_ix\n",
    "        except Exception as e:\n",
    "            raise HousingException(e, sys) from e\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            room_per_household = X[:, 3] / \\\n",
    "                                 X[:, 6]\n",
    "            population_per_household = X[:, 5] / \\\n",
    "                                       X[:, 6]\n",
    "            if self.add_bedrooms_per_room:\n",
    "                bedrooms_per_room = X[:, 4] / \\\n",
    "                                    X[:, 3]\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household, bedrooms_per_room]\n",
    "            else:\n",
    "                generated_feature = np.c_[\n",
    "                    X, room_per_household, population_per_household]\n",
    "\n",
    "            return generated_feature\n",
    "        except Exception as e:\n",
    "            raise HousingException(e, sys) from e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "\n",
    "    def __init__(self, data_transformation_config: DataTransfrmationConfig,\n",
    "                 data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_artifact: DataValidationArtifacts\n",
    "                 ):\n",
    "        try:\n",
    "            logging.info(f\"{'>>' * 30}Data Transformation log started.{'<<' * 30} \")\n",
    "            self.data_transformation_config= data_transformation_config\n",
    "            self.data_ingestion_artifact = data_ingestion_artifact\n",
    "            self.data_validation_artifact = data_validation_artifact\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HousingException(e,sys) from e\n",
    "\n",
    "    \n",
    "\n",
    "    def get_data_transformer_object(self)->ColumnTransformer:\n",
    "        try:\n",
    "            # schema_file_path = self.data_validation_artifact.schema_file_path\n",
    "            schema_file_path = r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\config\\schema.yaml'\n",
    "\n",
    "            dataset_schema = read_yaml(schema_file_path)\n",
    "            \n",
    "\n",
    "            numerical_columns = dataset_schema[SCHEMA_NUMERICAL_COLUMN_KEY]\n",
    "            print(numerical_columns)\n",
    "            categorical_columns = dataset_schema[SCHEMA_CATEGORICAL_COLUMN_KEY]\n",
    "\n",
    "\n",
    "            num_pipeline = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                ('feature_generator', FeatureGenerator(\n",
    "                    add_bedrooms_per_room=self.data_transformation_config.add_bedroom_per_room,\n",
    "                    columns=numerical_columns\n",
    "                )),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline = Pipeline(steps=[\n",
    "                 ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                 ('one_hot_encoder', OneHotEncoder()),\n",
    "                 ('scaler', StandardScaler(with_mean=False))\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            logging.info(f\"Categorical columns: {categorical_columns}\")\n",
    "            logging.info(f\"Numerical columns: {numerical_columns}\")\n",
    "            dataset = pd.read_csv(r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\artifact\\data_ingestion\\2024-03-26-10-55-20\\ingested_data\\test\\test_data_housing.csv')\n",
    "\n",
    "            numerical_column = dataset_schema[SCHEMA_NUMERICAL_COLUMN_KEY].split(\" \")\n",
    "            categorical_column =dataset_schema[SCHEMA_CATEGORICAL_COLUMN_KEY].split(\" \")\n",
    "\n",
    "            # numerical_columns = dataset.select_dtypes(exclude='object').columns\n",
    "            # categorical_columns =dataset.select_dtypes(include='object').columns\n",
    "\n",
    "            preprocessing = ColumnTransformer([\n",
    "                ('num_pipeline', num_pipeline, numerical_column),\n",
    "                ('cat_pipeline', cat_pipeline, categorical_column),\n",
    "            ])\n",
    "            return preprocessing\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HousingException(e,sys) from e   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude latitude housing_median_age total_rooms total_bedrooms population households median_income\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\artifact\\data_ingestion\\2024-03-26-10-55-20\\ingested_data\\train\\train_data_housing.csv')\n",
    "datatransform =DataTransformation(\n",
    "    data_transformation_config= DataTransfrmationConfig ,\n",
    "    data_ingestion_artifact=DataIngestionArtifact ,\n",
    "    data_validation_artifact= DataValidationArtifacts\n",
    ")\n",
    "processor_ =datatransform.get_data_transformer_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\artifact\\data_ingestion\\2024-03-26-10-55-20\\ingested_data\\test\\test_data_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57507019, -0.69657252,  0.0329564 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.43480141, -0.33466769, -0.36298077, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.54522177, -0.63547171,  0.58726843, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.08656982, -0.54617051,  1.14158047, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.81385757, -0.92687559,  0.11214383, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.49049967, -0.66367208,  0.58726843, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor_.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema =r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\config\\schema.yaml'\n",
    "read_yaml(schema)['numerical_column'].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_path = ('D:\\Data Science\\\\MachineLearning\\\\Project\\\\MachineLearningProject1\\\\artifact\\\\transformed_data_dir\\\\2024-03-26-12-24-15\\\\test\\\\test_data_housing.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array2(file_path: str) -> np.array:\n",
    "    \"\"\"\n",
    "    load numpy array data from file\n",
    "    file_path: str location of file to load\n",
    "    return: np.array data loaded\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file_obj:\n",
    "            return np.load(file_obj)\n",
    "    except Exception as e:\n",
    "        raise HousingException(e, sys) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.92294223e-01, -7.10658034e-01,  2.75635714e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.00001000e+05],\n",
       "       [-4.21809589e-01, -3.50491190e-01, -3.70068519e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.62500000e+05],\n",
       "       [ 5.62320712e-01, -6.49850644e-01,  5.84248498e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.04600000e+05],\n",
       "       ...,\n",
       "       [-7.21186193e-02, -5.60978306e-01,  1.14093342e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.93800000e+05],\n",
       "       [ 8.32082317e-01, -9.39855116e-01,  1.07089989e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.35700000e+05],\n",
       "       [ 5.07369274e-01, -6.77915593e-01,  5.84248498e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.15600000e+05]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_array2(r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\artifact\\transformed_data_dir\\2024-03-26-12-24-15\\test\\test_data_housing.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Housing.src.utils.utils import load_array\n",
    "# load_array(r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\artifact\\transformed_data_dir\\2024-03-26-12-24-15\\test\\test_data_housing.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.92294223e-01, -7.10658034e-01,  2.75635714e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.00001000e+05],\n",
       "       [-4.21809589e-01, -3.50491190e-01, -3.70068519e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.62500000e+05],\n",
       "       [ 5.62320712e-01, -6.49850644e-01,  5.84248498e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.04600000e+05],\n",
       "       ...,\n",
       "       [-7.21186193e-02, -5.60978306e-01,  1.14093342e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.93800000e+05],\n",
       "       [ 8.32082317e-01, -9.39855116e-01,  1.07089989e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.35700000e+05],\n",
       "       [ 5.07369274e-01, -6.77915593e-01,  5.84248498e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.15600000e+05]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_array(r'D:\\Data Science\\MachineLearning\\Project\\MachineLearningProject1\\artifact\\transformed_data_dir\\2024-03-26-12-24-15\\test\\test_data_housing.npz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
